#!/usr/bin/env python3
"""
format_evolver.py â€” Nowpattern Format Evolver

æœˆ1å›å®Ÿè¡Œ: ä¸–ç•Œãƒˆãƒƒãƒ—ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ¬ã‚¿ãƒ¼ã‚’ã‚¹ã‚­ãƒ£ãƒ³ã—ã€
Nowpatternã®è¨˜äº‹ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’è‡ªå‹•ã§æœ€æ–°ã®ä¸–ç•Œæ°´æº–ã«æ›´æ–°ã™ã‚‹ã€‚

ä½¿ã„æ–¹:
  python3 format_evolver.py                    # é€šå¸¸å®Ÿè¡Œ
  python3 format_evolver.py --dry-run          # åˆ†æã®ã¿ï¼ˆæŒ‡ç¤ºæ›¸æ›´æ–°ãªã—ï¼‰

cron: 0 3 1 * * source /opt/cron-env.sh && python3 /opt/shared/scripts/format_evolver.py

ãƒ•ãƒ­ãƒ¼:
  1. ä¸–ç•Œã®ãƒˆãƒƒãƒ—10ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ¬ã‚¿ãƒ¼ã®æœ€æ–°è¨˜äº‹ã‚’RSS/Webã§Nä»¶å–å¾—
  2. Gemini 2.5 ProãŒæ§‹é€ ãƒ»ãƒˆãƒ¼ãƒ³ãƒ»ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯ã‚’åˆ†æ
  3. Nowpatternã¸ã®æ”¹å–„ææ¡ˆã‚’ãƒªã‚¹ãƒˆåŒ–
  4. æ”¹å–„ææ¡ˆã‚’ãƒ¬ãƒãƒ¼ãƒˆã¨ã—ã¦ä¿å­˜
  5. Telegramé€šçŸ¥ï¼ˆã‚ªãƒ¼ãƒŠãƒ¼ãŒç¢ºèªâ†’æ¡ç”¨åˆ¤æ–­ï¼‰

â€» æŒ‡ç¤ºæ›¸ã®è‡ªå‹•æ›´æ–°ã¯å±é™ºãªãŸã‚ã€ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ+Telegramé€šçŸ¥ã«ã¨ã©ã‚ã‚‹ã€‚
   ã‚ªãƒ¼ãƒŠãƒ¼ãŒæ‰¿èªã—ãŸæ”¹å–„æ¡ˆã®ã¿ã‚’æ‰‹å‹•ã§åæ˜ ã™ã‚‹ã€‚
"""

import json
import os
import sys
import argparse
import subprocess
from datetime import datetime, timezone

REPORT_DIR = "/opt/shared/reports"
SCRIPTS_DIR = "/opt/shared/scripts"
TELEGRAM_SCRIPT = "/opt/shared/scripts/send-telegram-message.py"

# ã‚¹ã‚­ãƒ£ãƒ³å¯¾è±¡ï¼ˆRSS URL or Web URLï¼‰
TOP_NEWSLETTERS = [
    {"name": "Stratechery", "url": "https://stratechery.com/feed/", "type": "rss"},
    {"name": "Axios", "url": "https://www.axios.com/feeds/feed.rss", "type": "rss"},
    {"name": "Morning Brew", "url": "https://www.morningbrew.com/daily/rss", "type": "rss"},
    {"name": "Ben Evans", "url": "https://www.ben-evans.com/feed", "type": "rss"},
    {"name": "Doomberg", "url": "https://doomberg.substack.com/feed", "type": "rss"},
    {"name": "Kyla Scanlon", "url": "https://kylascanlon.substack.com/feed", "type": "rss"},
    {"name": "The Hustle", "url": "https://thehustle.co/feed/", "type": "rss"},
]

# åˆ†æãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
ANALYSIS_PROMPT = """ã‚ãªãŸã¯ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ¬ã‚¿ãƒ¼ãƒ»ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æˆ¦ç•¥ã®ä¸–ç•Œçš„å°‚é–€å®¶ã§ã™ã€‚

ä»¥ä¸‹ã®ä¸–ç•Œãƒˆãƒƒãƒ—ã‚¯ãƒ©ã‚¹ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ¬ã‚¿ãƒ¼è¨˜äº‹ã‚’åˆ†æã—ã€Nowpattern.comã®è¨˜äº‹ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’æ”¹å–„ã™ã‚‹ãŸã‚ã®å…·ä½“çš„ãªææ¡ˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

ã€Nowpatternã®ç¾åœ¨ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆv4.0ï¼‰ã€‘
1. BOTTOM LINEï¼ˆTL;DR: 1æ–‡ã®æ ¸å¿ƒ + ãƒ‘ã‚¿ãƒ¼ãƒ³å + åŸºæœ¬ã‚·ãƒŠãƒªã‚ª + æ³¨ç›®ãƒã‚¤ãƒ³ãƒˆï¼‰
2. ã‚¿ã‚°ãƒãƒƒã‚¸ï¼ˆã‚¸ãƒ£ãƒ³ãƒ«/ã‚¤ãƒ™ãƒ³ãƒˆ/åŠ›å­¦ï¼‰
3. Why it mattersï¼ˆ2-3æ–‡ï¼‰
4. What happenedï¼ˆäº‹å®Ÿè¦ç´„ã€300èªï¼‰
5. The Big Pictureï¼ˆæ­´å²çš„æ–‡è„ˆ + åˆ©å®³é–¢ä¿‚è€… + ãƒ‡ãƒ¼ã‚¿ï¼‰
6. Between the Linesï¼ˆå ±é“ãŒè¨€ã£ã¦ã„ãªã„ã“ã¨ï¼‰
7. NOW PATTERNï¼ˆåŠ›å­¦åˆ†æã€ãƒ€ãƒ¼ã‚¯ãƒœãƒƒã‚¯ã‚¹ï¼‰
8. Pattern Historyï¼ˆæ­´å²çš„ä¸¦è¡Œäº‹ä¾‹ï¼‰
9. What's Nextï¼ˆ3ã‚·ãƒŠãƒªã‚ª+ç¢ºç‡+ç¤ºå”†ï¼‰
10. Open Loopï¼ˆæ¬¡ã®ãƒˆãƒªã‚¬ãƒ¼ + è¿½è·¡ãƒ†ãƒ¼ãƒï¼‰

ã€åˆ†æã—ã¦ã»ã—ã„ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ¬ã‚¿ãƒ¼è¨˜äº‹ã€‘
{articles}

ã€å›ç­”ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã€‘
ä»¥ä¸‹ã®JSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„:
{{
  "analysis_date": "YYYY-MM-DD",
  "newsletters_analyzed": ["åå‰1", "åå‰2", ...],
  "observations": [
    {{
      "newsletter": "ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ¬ã‚¿ãƒ¼å",
      "technique": "ç™ºè¦‹ã—ãŸãƒ†ã‚¯ãƒ‹ãƒƒã‚¯å",
      "description": "ä½•ã‚’ã‚„ã£ã¦ã„ã‚‹ã‹ï¼ˆå…·ä½“çš„ã«ï¼‰",
      "example": "è¨˜äº‹ã‹ã‚‰ã®å…·ä½“ä¾‹",
      "applicability": "Nowpatternã«ã©ã†é©ç”¨ã§ãã‚‹ã‹",
      "impact": "high/medium/low",
      "effort": "high/medium/low"
    }}
  ],
  "top_3_recommendations": [
    {{
      "title": "æ”¹å–„ææ¡ˆã‚¿ã‚¤ãƒˆãƒ«",
      "description": "å…·ä½“çš„ãªæ”¹å–„å†…å®¹",
      "rationale": "ãªãœã“ã®æ”¹å–„ãŒåŠ¹æœçš„ã‹",
      "implementation": "ã©ã†ã‚„ã£ã¦å®Ÿè£…ã™ã‚‹ã‹"
    }}
  ],
  "format_health_score": 85,
  "summary": "å…¨ä½“ã¾ã¨ã‚ï¼ˆ3-4æ–‡ï¼‰"
}}
"""


def fetch_rss_articles(url, max_items=3):
    """RSSãƒ•ã‚£ãƒ¼ãƒ‰ã‹ã‚‰æœ€æ–°Nä»¶ã®è¨˜äº‹ã‚’å–å¾—"""
    try:
        import feedparser
        feed = feedparser.parse(url)
        articles = []
        for entry in feed.entries[:max_items]:
            articles.append({
                "title": entry.get("title", ""),
                "link": entry.get("link", ""),
                "summary": entry.get("summary", "")[:1000],
                "published": entry.get("published", ""),
            })
        return articles
    except Exception as e:
        print(f"  RSSå–å¾—å¤±æ•—({url[:50]}): {e}")
        return []


def scrape_article_text(url, timeout=15):
    """è¨˜äº‹URLã‹ã‚‰æœ¬æ–‡ã‚’å–å¾—"""
    try:
        from curl_cffi import requests as cffi_requests
        from bs4 import BeautifulSoup

        resp = cffi_requests.get(url, impersonate="chrome", timeout=timeout, allow_redirects=True)
        if resp.status_code != 200:
            return ""

        soup = BeautifulSoup(resp.text, "lxml")
        for tag in soup.find_all(["script", "style", "nav", "footer", "header", "aside"]):
            tag.decompose()

        article = soup.find("article")
        text = (article or soup).get_text(separator="\n", strip=True)
        return text[:3000] if len(text) > 3000 else text
    except Exception as e:
        print(f"  ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ—å¤±æ•—({url[:50]}): {e}")
        return ""


def analyze_with_gemini(articles_text):
    """Gemini 2.5 Proã§è¨˜äº‹ã‚’åˆ†æ"""
    api_key = os.environ.get("GEMINI_API_KEY", "") or os.environ.get("GOOGLE_API_KEY", "")
    if not api_key:
        print("ERROR: GEMINI_API_KEY / GOOGLE_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return None

    try:
        import google.generativeai as genai
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel("gemini-2.5-pro-preview-05-06")

        prompt = ANALYSIS_PROMPT.replace("{articles}", articles_text)
        response = model.generate_content(prompt)

        # JSONã‚’æŠ½å‡º
        text = response.text
        if "```json" in text:
            text = text.split("```json")[1].split("```")[0]
        elif "```" in text:
            text = text.split("```")[1].split("```")[0]

        return json.loads(text)
    except Exception as e:
        print(f"  Geminiåˆ†æå¤±æ•—: {e}")
        return None


def send_telegram_notification(report):
    """Telegramé€šçŸ¥"""
    summary = report.get("summary", "åˆ†æå®Œäº†")
    recs = report.get("top_3_recommendations", [])

    message = f"ğŸ“Š Format Evolver æœˆæ¬¡ãƒ¬ãƒãƒ¼ãƒˆ\n\n"
    message += f"åˆ†æå¯¾è±¡: {', '.join(report.get('newsletters_analyzed', []))}\n"
    message += f"ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¥å…¨åº¦: {report.get('format_health_score', '?')}/100\n\n"
    message += f"ğŸ“ ã‚µãƒãƒªãƒ¼:\n{summary}\n\n"

    if recs:
        message += "ğŸ† Top 3 æ”¹å–„ææ¡ˆ:\n"
        for i, r in enumerate(recs, 1):
            message += f"{i}. {r.get('title', '')}\n   â†’ {r.get('description', '')[:100]}\n\n"

    message += f"è©³ç´°: /opt/shared/reports/ ã‚’ç¢ºèª"

    try:
        if os.path.exists(TELEGRAM_SCRIPT):
            subprocess.run(
                ["python3", TELEGRAM_SCRIPT, message],
                capture_output=True, text=True, timeout=15
            )
    except Exception:
        pass

    return message


def run_evolver(dry_run=False):
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("ğŸ”„ Nowpattern Format Evolver èµ·å‹•")
    print(f"   åˆ†æå¯¾è±¡: {len(TOP_NEWSLETTERS)} ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ¬ã‚¿ãƒ¼")

    # Step 1: è¨˜äº‹åé›†
    print("\nStep 1: è¨˜äº‹åé›†ä¸­...")
    all_articles = []
    for nl in TOP_NEWSLETTERS:
        print(f"  ğŸ“° {nl['name']}...")
        if nl["type"] == "rss":
            articles = fetch_rss_articles(nl["url"], max_items=2)
            for a in articles:
                a["newsletter"] = nl["name"]
                # æœ¬æ–‡ã‚‚ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ—ï¼ˆãƒ™ã‚¹ãƒˆã‚¨ãƒ•ã‚©ãƒ¼ãƒˆï¼‰
                if a.get("link"):
                    a["full_text"] = scrape_article_text(a["link"])
            all_articles.extend(articles)

    print(f"  â†’ {len(all_articles)} è¨˜äº‹ã‚’åé›†")

    if not all_articles:
        print("è¨˜äº‹ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
        return

    # Step 2: åˆ†æç”¨ãƒ†ã‚­ã‚¹ãƒˆæ§‹ç¯‰
    articles_text = ""
    for a in all_articles:
        articles_text += f"\n=== {a.get('newsletter', '')} ===\n"
        articles_text += f"Title: {a.get('title', '')}\n"
        articles_text += f"Summary: {a.get('summary', '')[:500]}\n"
        if a.get("full_text"):
            articles_text += f"Body (excerpt): {a['full_text'][:1500]}\n"
        articles_text += "\n"

    if dry_run:
        print(f"\n[DRY-RUN] åˆ†æãƒ†ã‚­ã‚¹ãƒˆ: {len(articles_text)} æ–‡å­—")
        print(f"[DRY-RUN] Geminiåˆ†æã¯ã‚¹ã‚­ãƒƒãƒ—")
        return

    # Step 3: Geminiåˆ†æ
    print("\nStep 2: Geminiåˆ†æä¸­...")
    report = analyze_with_gemini(articles_text)

    if not report:
        print("åˆ†æã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
        return

    # Step 4: ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
    date_str = datetime.now().strftime("%Y-%m-%d")
    report_path = os.path.join(REPORT_DIR, f"{date_str}_format-evolver-report.json")
    os.makedirs(REPORT_DIR, exist_ok=True)
    with open(report_path, "w", encoding="utf-8") as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    print(f"\nStep 3: ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {report_path}")

    # Step 5: Telegramé€šçŸ¥
    print("Step 4: Telegramé€šçŸ¥...")
    msg = send_telegram_notification(report)
    print(msg[:200])

    # çµæœã‚µãƒãƒªãƒ¼
    print(f"\n=== Format Evolver å®Œäº† ===")
    print(f"ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¥å…¨åº¦: {report.get('format_health_score', '?')}/100")
    observations = report.get("observations", [])
    high_impact = [o for o in observations if o.get("impact") == "high"]
    print(f"ç™ºè¦‹: {len(observations)} ä»¶ï¼ˆé«˜ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆ: {len(high_impact)} ä»¶ï¼‰")
    print(f"æ”¹å–„ææ¡ˆ: {len(report.get('top_3_recommendations', []))} ä»¶")


def main():
    parser = argparse.ArgumentParser(description="Nowpattern Format Evolver â€” æœˆæ¬¡ä¸–ç•Œã‚¹ã‚­ãƒ£ãƒ³")
    parser.add_argument("--dry-run", action="store_true", help="è¨˜äº‹åé›†ã®ã¿ï¼ˆåˆ†æãƒ»æ›´æ–°ãªã—ï¼‰")
    args = parser.parse_args()

    run_evolver(dry_run=args.dry_run)


if __name__ == "__main__":
    main()
