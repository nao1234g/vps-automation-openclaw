#!/usr/bin/env python3
"""
Hey Loop Intelligence Feed v2.0
================================
è¨­è¨ˆå›³: docs/HEY_LOOP_V2_DESIGN.md

Layer 0: Pythonåé›†ï¼ˆRSS/Reddit/HN/GitHub/Grok â€” LLMãªã—ï¼‰
Layer 1: Opus 4.6 å…¨åˆ¤æ–­ï¼ˆclaude --print + Read toolï¼‰
Layer 2: Telegramå ±å‘Šï¼ˆ200å­—ä»¥å†…ï¼‰
Layer 3: state.json é–‰ãƒ«ãƒ¼ãƒ—ï¼ˆå‰å›æ–‡è„ˆã‚’æ¬¡å›ã«å¼•ãç¶™ãï¼‰
Layer 4: é€±æ¬¡è‡ªå·±é€²åŒ–ï¼ˆAGENT_WISDOM.md è‡ªå‹•æ›´æ–°ï¼‰

ç‰¹åˆ¥ç›£è¦–: Claude Code / OpenClaw â€” å¤‰åŒ–ãŒã‚ã‚Œã°å³ã‚¢ãƒ©ãƒ¼ãƒˆ

ã€Œ9å‰²å‰Šæ¸›ã€æŠ€è¡“:
  ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ã â†’ claude --print ã§ Opus ãŒ Read ãƒ„ãƒ¼ãƒ«ã§èª­ã‚€
  ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯ ~50ãƒˆãƒ¼ã‚¯ãƒ³ã€‚æ¯å›æ–°é®®ã‚»ãƒƒã‚·ãƒ§ãƒ³ï¼ˆæ–‡è„ˆè“„ç©ãªã—ï¼‰

Usage:
  python3 intelligence-feed-v2.py            # ãƒ•ãƒ«å®Ÿè¡Œï¼ˆcollect + synthï¼‰
  python3 intelligence-feed-v2.py --collect  # Layer 0 ã®ã¿ï¼ˆLLMãªã—ï¼‰
  python3 intelligence-feed-v2.py --synth    # Layer 1 ã®ã¿ï¼ˆOpusåˆæˆï¼‰
  python3 intelligence-feed-v2.py --evolve   # Layer 4ï¼ˆé€±æ¬¡é€²åŒ–ï¼‰
  python3 intelligence-feed-v2.py --dry-run  # Telegramé€ä¿¡ãªã—ï¼ˆãƒ†ã‚¹ãƒˆï¼‰

VPS cron è¨­å®š:
  */30 * * * *  python3 /opt/shared/scripts/intelligence-feed-v2.py --collect
  0 */3 * * *   python3 /opt/shared/scripts/intelligence-feed-v2.py --synth
  0 23 * * 0    python3 /opt/shared/scripts/intelligence-feed-v2.py --evolve
"""

import argparse
import json
import os
import subprocess
import sys
import time
import xml.etree.ElementTree as ET
from datetime import datetime, timezone, timedelta
from pathlib import Path

import urllib.request
import urllib.error

# =============================================================================
# Config
# =============================================================================

JST = timezone(timedelta(hours=9))

INTEL_DIR = "/opt/shared/intelligence"
RAW_DIR = f"{INTEL_DIR}/raw"
SYNTH_DIR = f"{INTEL_DIR}/synthesis"
WEEKLY_DIR = f"{INTEL_DIR}/weekly"
STATE_FILE = f"{INTEL_DIR}/state.json"
AGENT_WISDOM_FILE = "/opt/shared/AGENT_WISDOM.md"

# Claude ãƒã‚¤ãƒŠãƒªå€™è£œï¼ˆVPSç’°å¢ƒï¼‰
CLAUDE_BIN_CANDIDATES = [
    "/root/.nvm/versions/node/v22.14.0/bin/claude",
    "/opt/claude-code-telegram/node_modules/.bin/claude",
    "/usr/local/bin/claude",
    "/root/.local/bin/claude",
]

# =============================================================================
# RSS ãƒ•ã‚£ãƒ¼ãƒ‰ï¼ˆAIå…¨èˆ¬ + Claude/OpenClawç‰¹åˆ¥ç›£è¦–ï¼‰
# =============================================================================
RSS_FEEDS = [
    # --- Claude Code / OpenClaw æœ€é‡è¦ç›£è¦– ---
    {
        "name": "Anthropic Blog",
        "url": "https://www.anthropic.com/rss.xml",
        "category": "claude_watch",
        "priority": "critical",
    },
    # --- AIç ”ç©¶ãƒ»ãƒ¢ãƒ‡ãƒ«å‹•å‘ ---
    {
        "name": "Hugging Face Blog",
        "url": "https://huggingface.co/blog.rss",
        "category": "ai_research",
        "priority": "high",
    },
    {
        "name": "arXiv cs.AI",
        "url": "https://arxiv.org/rss/cs.AI",
        "category": "ai_research",
        "priority": "medium",
    },
    # --- AIæ¥­ç•Œãƒ‹ãƒ¥ãƒ¼ã‚¹ ---
    {
        "name": "VentureBeat AI",
        "url": "https://venturebeat.com/category/ai/feed/",
        "category": "ai_business",
        "priority": "high",
    },
    {
        "name": "TechCrunch AI",
        "url": "https://techcrunch.com/tag/artificial-intelligence/feed/",
        "category": "ai_business",
        "priority": "medium",
    },
    {
        "name": "The Verge AI",
        "url": "https://www.theverge.com/ai-artificial-intelligence/rss/index.xml",
        "category": "ai_news",
        "priority": "medium",
    },
    {
        "name": "MIT Technology Review AI",
        "url": "https://www.technologyreview.com/tag/artificial-intelligence/feed/",
        "category": "ai_research",
        "priority": "medium",
    },
    {
        "name": "Wired AI",
        "url": "https://www.wired.com/feed/tag/artificial-intelligence/latest/rss",
        "category": "ai_news",
        "priority": "low",
    },
]

# =============================================================================
# Reddit ã‚µãƒ–ãƒ¬ãƒ‡ã‚£ãƒƒãƒˆ
# =============================================================================
SUBREDDITS = [
    # Claude Code / OpenClaw ç‰¹åˆ¥ç›£è¦–
    {"name": "ClaudeAI", "category": "claude_watch", "limit": 15},
    # AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ„ãƒ¼ãƒ«
    {"name": "LocalLLaMA", "category": "ai_tools", "limit": 10},
    {"name": "AI_Agents", "category": "ai_tools", "limit": 10},
    {"name": "artificial", "category": "ai_news", "limit": 8},
    {"name": "MachineLearning", "category": "ai_research", "limit": 8},
    {"name": "Singularity", "category": "ai_news", "limit": 5},
    # åç›Šã‚·ã‚°ãƒŠãƒ«
    {"name": "SideProject", "category": "revenue", "limit": 10},
    {"name": "SaaS", "category": "revenue", "limit": 8},
    {"name": "indiehackers", "category": "revenue", "limit": 8},
    {"name": "Entrepreneur", "category": "revenue", "limit": 8},
    {"name": "EntrepreneurRideAlong", "category": "revenue", "limit": 8},
    # ã‚¤ãƒ³ãƒ•ãƒ©
    {"name": "n8n", "category": "infra", "limit": 5},
    {"name": "selfhosted", "category": "infra", "limit": 5},
    {"name": "docker", "category": "infra", "limit": 5},
]

# =============================================================================
# GitHub ãƒªãƒã‚¸ãƒˆãƒªç›£è¦–
# =============================================================================
GITHUB_REPOS = [
    # --- Claude Code / OpenClaw æœ€é‡è¦ ---
    {
        "repo": "anthropics/anthropic-sdk-python",
        "category": "claude_watch",
        "priority": "critical",
    },
    {
        "repo": "open-claw/open-claw",
        "category": "claude_watch",
        "priority": "critical",
    },
    # --- AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ„ãƒ¼ãƒ«ç«¶åˆè¿½è·¡ ---
    {
        "repo": "continuedev/continue",
        "category": "ai_tools_competitor",
        "priority": "high",
    },
    {
        "repo": "BerriAI/litellm",
        "category": "ai_tools",
        "priority": "high",
    },
    {
        "repo": "langgenius/dify",
        "category": "ai_tools",
        "priority": "medium",
    },
    {
        "repo": "microsoft/autogen",
        "category": "ai_tools",
        "priority": "medium",
    },
    {
        "repo": "joaomdmoura/crewAI",
        "category": "ai_tools",
        "priority": "medium",
    },
    {
        "repo": "n8n-io/n8n",
        "category": "infra",
        "priority": "high",
    },
    {
        "repo": "Mintplex-Labs/anything-llm",
        "category": "ai_tools",
        "priority": "low",
    },
    {
        "repo": "assafelovic/gpt-researcher",
        "category": "ai_tools",
        "priority": "low",
    },
]

# =============================================================================
# HN ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
# =============================================================================
HN_KEYWORDS = [
    # Claude Code / OpenClaw æœ€é‡è¦
    "claude code", "claude", "anthropic", "open-claw", "openclaw",
    # AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ„ãƒ¼ãƒ«å…¨èˆ¬
    "ai agent", "llm", "gpt", "gemini", "grok", "mistral", "cursor",
    "copilot", "devin", "continue", "codeium", "model", "ai tool",
    # ãƒ“ã‚¸ãƒã‚¹ãƒ»åç›Š
    "revenue", "mrr", "saas", "newsletter", "indie hacker", "startup",
    "automation", "side project", "monetize",
    # ã‚¤ãƒ³ãƒ•ãƒ©
    "n8n", "self-hosted", "docker", "openai", "deepmind", "meta ai",
]

# Grok Xæ¤œç´¢ã‚¯ã‚¨ãƒªï¼ˆ4æœ¬ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
GROK_QUERIES = [
    (
        "Search X/Twitter for the last 48h: Claude Code power users sharing tips, "
        "tricks, CLAUDE.md setups, and workflows. Also find comparisons between "
        "Claude Code vs Cursor vs Copilot vs Devin. Include usernames and URLs."
    ),
    (
        "Search X/Twitter for the last 48h: people sharing their AI automation "
        "revenue, MRR, client results. Indie hackers building AI SaaS or newsletters "
        "with concrete numbers. Include @username, revenue figures, and post URLs."
    ),
    (
        "Search X/Twitter for the last 48h: new AI tools, agent frameworks, or "
        "services that just launched. Anything that could be better than current "
        "tools (OpenClaw, n8n, LiteLLM etc). Include product names and URLs."
    ),
    (
        "Search X/Twitter for the last 48h: AI model pricing changes, free tier "
        "updates, API cost reductions from Anthropic, OpenAI, Google, xAI. "
        "Include specific numbers and effective dates."
    ),
]


# =============================================================================
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# =============================================================================

def now_jst() -> datetime:
    return datetime.now(JST)


def log(msg: str):
    ts = now_jst().strftime("%H:%M:%S")
    print(f"[{ts}] {msg}")


def ensure_dirs():
    for d in [INTEL_DIR, RAW_DIR, SYNTH_DIR, WEEKLY_DIR]:
        Path(d).mkdir(parents=True, exist_ok=True)


def find_claude_bin() -> str | None:
    """Claude CLIãƒã‚¤ãƒŠãƒªã‚’æ¢ã™ã€‚"""
    import shutil
    # PATH ã‹ã‚‰æ¢ã™
    found = shutil.which("claude")
    if found:
        return found
    # å€™è£œãƒ‘ã‚¹ã‹ã‚‰æ¢ã™
    for path in CLAUDE_BIN_CANDIDATES:
        if os.path.exists(path):
            return path
    return None


def get_api_keys() -> dict:
    """å„ç¨®APIã‚­ãƒ¼ã‚’ç’°å¢ƒå¤‰æ•°ã¨.envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å–å¾—ã€‚"""
    keys = {
        "google": os.environ.get("GOOGLE_API_KEY"),
        "xai": os.environ.get("XAI_API_KEY"),
        "telegram_token": os.environ.get("TELEGRAM_BOT_TOKEN"),
        "telegram_chat": os.environ.get("ALLOWED_USERS"),
    }
    env_paths = [
        "/opt/cron-env.sh",
        "/opt/claude-code-telegram/.env",
        "/opt/shared/.env",
        "/opt/openclaw/.env",
    ]
    for path in env_paths:
        if not os.path.exists(path):
            continue
        try:
            with open(path) as f:
                for line in f:
                    line = line.strip()
                    # export KEY=VALUE ã¾ãŸã¯ KEY=VALUE å½¢å¼ã«å¯¾å¿œ
                    if line.startswith("export "):
                        line = line[7:]
                    if "=" not in line or line.startswith("#"):
                        continue
                    k, _, v = line.partition("=")
                    k = k.strip()
                    v = v.strip().strip('"').strip("'")
                    if k == "GOOGLE_API_KEY" and not keys["google"]:
                        keys["google"] = v
                    elif k == "XAI_API_KEY" and not keys["xai"]:
                        keys["xai"] = v
                    elif k == "TELEGRAM_BOT_TOKEN" and not keys["telegram_token"]:
                        keys["telegram_token"] = v
                    elif k == "ALLOWED_USERS" and not keys["telegram_chat"]:
                        keys["telegram_chat"] = v
        except Exception:
            pass
    return keys


def load_state() -> dict:
    """å‰å›ã®çŠ¶æ…‹ã‚’èª­ã¿è¾¼ã‚€ï¼ˆãªã‘ã‚Œã°ç©ºã®çŠ¶æ…‹ã‚’è¿”ã™ï¼‰ã€‚"""
    if os.path.exists(STATE_FILE):
        try:
            with open(STATE_FILE) as f:
                return json.load(f)
        except Exception:
            pass
    return {
        "last_synthesis": None,
        "acted_on": [],
        "skipped": [],
        "top_claude_code_version": None,
        "top_openclaw_version": None,
        "known_best_ai_agent_tool": "open-claw",
        "article_pipeline": [],
        "next_context": "åˆå›å®Ÿè¡Œã€‚éå»ã®æ–‡è„ˆãªã—ã€‚",
        "weekly_insights": [],
    }


def save_state(state: dict):
    try:
        with open(STATE_FILE, "w") as f:
            json.dump(state, f, ensure_ascii=False, indent=2)
        log(f"  state.json ä¿å­˜: {STATE_FILE}")
    except Exception as e:
        log(f"  state.json ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")


# =============================================================================
# Layer 0: åé›†é–¢æ•°
# =============================================================================

def fetch_rss(feed: dict) -> list[dict]:
    """RSS ãƒ•ã‚£ãƒ¼ãƒ‰ã‚’å–å¾—ã—ã¦ã‚¢ã‚¤ãƒ†ãƒ ãƒªã‚¹ãƒˆã‚’è¿”ã™ã€‚"""
    url = feed["url"]
    try:
        req = urllib.request.Request(
            url,
            headers={"User-Agent": "HeyLoopIntelligence/2.0 (AI monitoring)"},
        )
        with urllib.request.urlopen(req, timeout=20) as resp:
            raw = resp.read().decode("utf-8", errors="replace")

        root = ET.fromstring(raw)
        # RSS 2.0
        ns = {}
        items = root.findall(".//item")
        # Atom ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        if not items:
            atom_ns = "http://www.w3.org/2005/Atom"
            items = root.findall(f".//{{{atom_ns}}}entry")

        results = []
        for item in items[:10]:
            title = (
                item.findtext("title") or
                item.findtext(f"{{{atom_ns}}}title") if not item.findtext("title") else item.findtext("title")
            )
            link = (
                item.findtext("link") or
                (item.find("link").get("href") if item.find("link") is not None else "")
            )
            pub = item.findtext("pubDate") or item.findtext("published") or ""
            desc = (item.findtext("description") or item.findtext("summary") or "")[:400]
            if title:
                results.append({
                    "title": (title or "").strip(),
                    "url": (link or "").strip(),
                    "published": pub.strip(),
                    "summary": desc.strip(),
                    "source": feed["name"],
                    "category": feed["category"],
                    "priority": feed["priority"],
                })
        log(f"  RSS [{feed['name']}]: {len(results)} ä»¶")
        return results
    except Exception as e:
        log(f"  RSS [{feed['name']}] ã‚¨ãƒ©ãƒ¼: {e}")
        return []


def fetch_reddit(sub: dict) -> list[dict]:
    """Reddit ã‚µãƒ–ãƒ¬ãƒ‡ã‚£ãƒƒãƒˆã®ãƒ›ãƒƒãƒˆæŠ•ç¨¿ã‚’å–å¾—ã€‚"""
    url = f"https://www.reddit.com/r/{sub['name']}/hot.json?limit={sub['limit']}"
    req = urllib.request.Request(
        url,
        headers={"User-Agent": "HeyLoopIntelligence/2.0 (non-commercial research)"},
    )
    try:
        with urllib.request.urlopen(req, timeout=15) as resp:
            data = json.loads(resp.read().decode("utf-8"))
        posts = []
        for child in data.get("data", {}).get("children", []):
            d = child["data"]
            if d.get("stickied"):
                continue
            posts.append({
                "title": d.get("title", ""),
                "score": d.get("score", 0),
                "comments": d.get("num_comments", 0),
                "url": d.get("url", ""),
                "reddit_url": "https://reddit.com" + d.get("permalink", ""),
                "selftext": (d.get("selftext") or "")[:300],
                "subreddit": sub["name"],
                "category": sub["category"],
            })
        # ã‚¹ã‚³ã‚¢é †ã«ã‚½ãƒ¼ãƒˆ
        posts.sort(key=lambda p: p["score"], reverse=True)
        log(f"  Reddit r/{sub['name']}: {len(posts)} ä»¶")
        return posts
    except Exception as e:
        log(f"  Reddit r/{sub['name']} ã‚¨ãƒ©ãƒ¼: {e}")
        return []


def fetch_hn(limit: int = 50) -> list[dict]:
    """Hacker News ã®ãƒˆãƒƒãƒ—ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ•ã‚£ãƒ«ã‚¿ã—ã¦è¿”ã™ã€‚"""
    try:
        with urllib.request.urlopen(
            "https://hacker-news.firebaseio.com/v0/topstories.json", timeout=15
        ) as resp:
            ids = json.loads(resp.read().decode("utf-8"))[:limit]
    except Exception as e:
        log(f"  HN ãƒˆãƒƒãƒ—å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return []

    results = []
    for sid in ids:
        try:
            with urllib.request.urlopen(
                f"https://hacker-news.firebaseio.com/v0/item/{sid}.json", timeout=10
            ) as resp:
                item = json.loads(resp.read().decode("utf-8"))
            if not item:
                continue
            title_lower = (item.get("title") or "").lower()
            matched = next((kw for kw in HN_KEYWORDS if kw in title_lower), None)
            if matched:
                results.append({
                    "title": item.get("title", ""),
                    "url": item.get("url", ""),
                    "score": item.get("score", 0),
                    "comments": item.get("descendants", 0),
                    "hn_url": f"https://news.ycombinator.com/item?id={sid}",
                    "matched_keyword": matched,
                })
        except Exception:
            pass
        time.sleep(0.05)

    results.sort(key=lambda x: x["score"], reverse=True)
    log(f"  HN: {len(results)} ä»¶ï¼ˆtop {limit} ã‹ã‚‰ï¼‰")
    return results[:15]


def fetch_github(repos: list[dict]) -> list[dict]:
    """GitHub ãƒªãƒã‚¸ãƒˆãƒªã®æœ€æ–°ãƒªãƒªãƒ¼ã‚¹æƒ…å ±ã‚’å–å¾—ã€‚"""
    results = []
    for repo_info in repos:
        repo = repo_info["repo"]
        url = f"https://api.github.com/repos/{repo}/releases/latest"
        req = urllib.request.Request(
            url,
            headers={
                "User-Agent": "HeyLoopIntelligence/2.0",
                "Accept": "application/vnd.github+json",
            },
        )
        try:
            with urllib.request.urlopen(req, timeout=10) as resp:
                data = json.loads(resp.read().decode("utf-8"))
            results.append({
                "repo": repo,
                "tag": data.get("tag_name", ""),
                "name": data.get("name", ""),
                "published": data.get("published_at", ""),
                "body": (data.get("body") or "")[:600],
                "url": data.get("html_url", ""),
                "category": repo_info["category"],
                "priority": repo_info["priority"],
            })
            log(f"  GitHub {repo}: {data.get('tag_name', 'no release')}")
        except urllib.error.HTTPError as e:
            if e.code == 404:
                log(f"  GitHub {repo}: ãƒªãƒªãƒ¼ã‚¹ãªã—")
            else:
                log(f"  GitHub {repo}: HTTP {e.code}")
        except Exception as e:
            log(f"  GitHub {repo}: {e}")
        time.sleep(0.3)
    return results


def fetch_grok_x(xai_key: str, run_index: int) -> str | None:
    """Grok API ã§ X/Twitter ã‚’æ¤œç´¢ï¼ˆ6æ™‚é–“ã”ã¨ã®å‘¼ã³å‡ºã—æƒ³å®šï¼‰ã€‚"""
    query = GROK_QUERIES[run_index % len(GROK_QUERIES)]
    payload = {
        "model": "grok-3",
        "messages": [
            {
                "role": "system",
                "content": (
                    "You are an X/Twitter intelligence analyst. "
                    "Search for recent posts. Include @username, summary, "
                    "engagement if visible, and post URL. "
                    "Focus on concrete numbers and new tools."
                ),
            },
            {
                "role": "user",
                "content": (
                    f"{query}\n\n"
                    "Return top 5 most relevant posts. Format each as:\n"
                    "- @username: [summary]\n  URL: [url]\n  Signal: [key number or finding]"
                ),
            },
        ],
        "temperature": 0.3,
        "max_tokens": 1500,
    }
    data = json.dumps(payload).encode("utf-8")
    req = urllib.request.Request(
        "https://api.x.ai/v1/chat/completions",
        data=data,
        headers={
            "Content-Type": "application/json",
            "Authorization": f"Bearer {xai_key}",
        },
        method="POST",
    )
    try:
        with urllib.request.urlopen(req, timeout=60) as resp:
            result = json.loads(resp.read().decode("utf-8"))
        text = result["choices"][0]["message"]["content"]
        log(f"  Grok Xæ¤œç´¢: æˆåŠŸï¼ˆ{len(text)}å­—ï¼‰")
        return text
    except Exception as e:
        log(f"  Grok Xæ¤œç´¢ ã‚¨ãƒ©ãƒ¼: {e}")
        return None


# =============================================================================
# Layer 0: ãƒ¡ã‚¤ãƒ³åé›†
# =============================================================================

def collect(keys: dict, grok_enabled: bool = False) -> dict:
    """å…¨ã‚½ãƒ¼ã‚¹ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ã—ã¦JSONã«ä¿å­˜ã€‚"""
    log("=== Layer 0: ãƒ‡ãƒ¼ã‚¿åé›†é–‹å§‹ ===")
    ts = now_jst()

    raw_data = {
        "collected_at": ts.isoformat(),
        "rss": [],
        "reddit": [],
        "hn": [],
        "github": [],
        "grok_x": None,
    }

    # RSS
    log("RSS ãƒ•ã‚£ãƒ¼ãƒ‰åé›†ä¸­...")
    for feed in RSS_FEEDS:
        items = fetch_rss(feed)
        raw_data["rss"].extend(items)
        time.sleep(0.5)

    # Redditï¼ˆ30åˆ†ã”ã¨åé›†ã§ã¯ã‚µãƒ–ã‚»ãƒƒãƒˆã®ã¿ï¼‰
    log("Reddit åé›†ä¸­...")
    hour = ts.hour
    # å¥‡æ•°æ™‚é–“ã¯AIãƒ„ãƒ¼ãƒ«ç³»ã€å¶æ•°æ™‚é–“ã¯åç›Šç³»ã‚’å„ªå…ˆ
    subs_to_collect = SUBREDDITS if grok_enabled else SUBREDDITS[:8]
    for sub in subs_to_collect:
        posts = fetch_reddit(sub)
        raw_data["reddit"].extend(posts)
        time.sleep(1.0)

    # Hacker News
    log("HN åé›†ä¸­...")
    raw_data["hn"] = fetch_hn(limit=50)

    # GitHubï¼ˆ3æ™‚é–“ã”ã¨ = synth ã¨åŒã‚¿ã‚¤ãƒŸãƒ³ã‚°æƒ³å®šï¼‰
    log("GitHub åé›†ä¸­...")
    raw_data["github"] = fetch_github(GITHUB_REPOS)

    # Grok Xï¼ˆ6æ™‚é–“ã”ã¨ã€ãƒ•ãƒ©ã‚°ãŒã‚ã‚‹æ™‚ã®ã¿ï¼‰
    if grok_enabled and keys.get("xai"):
        log("Grok X æ¤œç´¢ä¸­...")
        run_idx = (hour // 6) % len(GROK_QUERIES)
        raw_data["grok_x"] = fetch_grok_x(keys["xai"], run_idx)
    else:
        log("  Grok X: ã‚¹ã‚­ãƒƒãƒ—ï¼ˆ--synth æ™‚ã®ã¿å®Ÿè¡Œï¼‰")

    # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
    filename = ts.strftime("%Y-%m-%d_%H%M") + ".json"
    filepath = os.path.join(RAW_DIR, filename)
    # latest.json ã‚‚å¸¸ã«ä¸Šæ›¸ãï¼ˆOpus ãŒèª­ã‚€ï¼‰
    latest_path = os.path.join(RAW_DIR, "latest.json")

    with open(filepath, "w") as f:
        json.dump(raw_data, f, ensure_ascii=False, indent=2)
    with open(latest_path, "w") as f:
        json.dump(raw_data, f, ensure_ascii=False, indent=2)

    total = (
        len(raw_data["rss"]) + len(raw_data["reddit"]) +
        len(raw_data["hn"]) + len(raw_data["github"])
    )
    log(f"åé›†å®Œäº†: {total} ä»¶ â†’ {filepath}")
    return raw_data


# =============================================================================
# Layer 1: Opus 4.6 åˆæˆï¼ˆclaude --printï¼‰
# =============================================================================

def build_opus_prompt(state: dict) -> str:
    """Opus ã«æ¸¡ã™ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆï¼ˆçŸ­ãã€ãƒ•ã‚¡ã‚¤ãƒ«å‚ç…§æ–¹å¼ï¼‰ã€‚"""
    state_summary = json.dumps(
        {
            "last_synthesis": state.get("last_synthesis"),
            "top_claude_code_version": state.get("top_claude_code_version"),
            "top_openclaw_version": state.get("top_openclaw_version"),
            "known_best_ai_agent_tool": state.get("known_best_ai_agent_tool"),
            "next_context": state.get("next_context"),
            "article_pipeline": state.get("article_pipeline", [])[:3],
        },
        ensure_ascii=False,
    )

    return f"""ã‚ãªãŸã¯Hey Loop v2.0ã®ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ã‚¹ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚

## å‰å›ã®çŠ¶æ…‹ï¼ˆé–‰ãƒ«ãƒ¼ãƒ—æ–‡è„ˆï¼‰
{state_summary}

## ã‚¿ã‚¹ã‚¯
ä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ Read ãƒ„ãƒ¼ãƒ«ã§èª­ã‚“ã§ãã ã•ã„:
- åé›†ãƒ‡ãƒ¼ã‚¿: {RAW_DIR}/latest.json

## ç‰¹åˆ¥ç›£è¦–é …ç›®ï¼ˆæœ€é‡è¦ï¼‰
- Claude Code: ãƒãƒ¼ã‚¸ãƒ§ãƒ³å¤‰åŒ–ãƒ»æ–°æ©Ÿèƒ½ãƒ»Breaking Change ã‚’å¿…ãšç¢ºèª
- OpenClaw: ãƒãƒ¼ã‚¸ãƒ§ãƒ³å¤‰åŒ–ãƒ»ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ä¿®æ­£ ã‚’å¿…ãšç¢ºèª
- ã€ŒOpenClawã‚ˆã‚Šå„ªã‚ŒãŸAIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ„ãƒ¼ãƒ«ã€ã®å‡ºç¾ã‚’æ¤œçŸ¥

## å‡ºåŠ›å½¢å¼ï¼ˆJSONã®ã¿ã€‚èª¬æ˜æ–‡ã¯ä¸€åˆ‡ä¸è¦ï¼‰
{{
  "top_insight": "æœ€é‡è¦ã®ç™ºè¦‹1ä»¶ï¼ˆæ—¥æœ¬èªã€1æ–‡ï¼‰",
  "action_for_naoto": "NaotoãŒä»Šã™ãå–ã‚Œã‚‹æœ€é«˜ä¾¡å€¤ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆæ—¥æœ¬èªã€1æ–‡ã€å…·ä½“çš„ã«ï¼‰",
  "claude_code_alert": "Claude Code/Anthropicã®å¤‰åŒ–ï¼ˆãªã‘ã‚Œã°nullï¼‰",
  "openclaw_alert": "OpenClawã®å¤‰åŒ–ï¼ˆãªã‘ã‚Œã°nullï¼‰",
  "better_tool_found": "OpenClawã‚ˆã‚Šå„ªã‚ŒãŸãƒ„ãƒ¼ãƒ«ã®ç™ºè¦‹ï¼ˆãªã‘ã‚Œã°nullï¼‰",
  "ai_developments": ["AIæ¥­ç•Œã®é‡è¦å‹•å‘ï¼ˆæœ€å¤§3ä»¶ï¼‰"],
  "revenue_signals": ["åç›Šã‚·ã‚°ãƒŠãƒ«ï¼ˆ@username + æ•°å­— + URLã€æœ€å¤§3ä»¶ï¼‰"],
  "article_ideas": ["Nowpatternè¨˜äº‹å€™è£œï¼ˆåŠ›å­¦ãƒ»ãƒ†ãƒ¼ãƒãƒ»è§’åº¦ã€æœ€å¤§2ä»¶ï¼‰"],
  "infrastructure_alerts": ["ã‚¤ãƒ³ãƒ•ãƒ©æ›´æ–°ãƒ»è„†å¼±æ€§ï¼ˆå¿…è¦ãªå ´åˆã®ã¿ã€æœ€å¤§2ä»¶ï¼‰"],
  "new_claude_code_version": "æ¤œå‡ºã—ãŸClaude Codeãƒãƒ¼ã‚¸ãƒ§ãƒ³ï¼ˆä¸æ˜ãªã‚‰nullï¼‰",
  "new_openclaw_version": "æ¤œå‡ºã—ãŸOpenClawãƒãƒ¼ã‚¸ãƒ§ãƒ³ï¼ˆä¸æ˜ãªã‚‰nullï¼‰",
  "next_context": "æ¬¡å›åˆ†æã®ãŸã‚ã®è¦ç‚¹ï¼ˆæ—¥æœ¬èªã€2-3æ–‡ï¼‰"
}}"""


def run_opus_synthesis(state: dict, dry_run: bool = False) -> dict | None:
    """claude --print ã§Opus 4.6ã«åˆæˆã•ã›ã‚‹ã€‚"""
    claude_bin = find_claude_bin()
    if not claude_bin:
        log("  âŒ claude CLI ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ‘ã‚¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        log(f"  ç¢ºèªå€™è£œ: {CLAUDE_BIN_CANDIDATES}")
        return None

    log(f"  Claude CLI: {claude_bin}")

    # åé›†ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
    latest_path = os.path.join(RAW_DIR, "latest.json")
    if not os.path.exists(latest_path):
        log(f"  âŒ åé›†ãƒ‡ãƒ¼ã‚¿ãªã—: {latest_path}")
        log("  å…ˆã« --collect ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
        return None

    prompt = build_opus_prompt(state)
    prompt_file = f"/tmp/hey_loop_opus_prompt_{now_jst().strftime('%H%M%S')}.txt"

    if dry_run:
        log("  [dry-run] Opus ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ:")
        print(prompt[:500] + "...")
        return {"dry_run": True, "prompt_preview": prompt[:200]}

    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ã„ã¦ stdin ã‹ã‚‰æ¸¡ã™ï¼ˆé•·ã„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå¯¾ç­–ï¼‰
    with open(prompt_file, "w") as f:
        f.write(prompt)

    log(f"  Opus 4.6 å‘¼ã³å‡ºã—ä¸­...")
    try:
        result = subprocess.run(
            [
                claude_bin,
                "--print",
                prompt,
                "--allowedTools", "Read",
                "--output-format", "text",
            ],
            capture_output=True,
            text=True,
            timeout=180,
            cwd=INTEL_DIR,  # CLAUDE.md ãŒã‚ã‚Œã°ã“ã“ã‹ã‚‰èª­ã‚€
        )
    except subprocess.TimeoutExpired:
        log("  âŒ Opus ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆ180ç§’ï¼‰")
        return None
    except Exception as e:
        log(f"  âŒ Opus å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        return None
    finally:
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
        if os.path.exists(prompt_file):
            os.remove(prompt_file)

    if result.returncode != 0:
        log(f"  âŒ Opus çµ‚äº†ã‚³ãƒ¼ãƒ‰ {result.returncode}")
        log(f"  stderr: {result.stderr[:300]}")
        # ãƒˆãƒ¼ã‚¯ãƒ³æœŸé™åˆ‡ã‚Œã®å¯èƒ½æ€§
        if "oauth" in result.stderr.lower() or "token" in result.stderr.lower():
            log("  âš ï¸ OAuthãƒˆãƒ¼ã‚¯ãƒ³ãŒæœŸé™åˆ‡ã‚Œã®å¯èƒ½æ€§ã€‚ãƒ­ãƒ¼ã‚«ãƒ«PCã§ claude setup-token ã‚’å®Ÿè¡Œã—ã¦VPSã«SCPã—ã¦ãã ã•ã„ã€‚")
        return None

    output = result.stdout.strip()
    log(f"  Opus å‡ºåŠ›: {len(output)} å­—")

    # JSON æŠ½å‡ºï¼ˆ```json ... ``` ãƒ–ãƒ­ãƒƒã‚¯ãŒã‚ã‚‹å ´åˆã‚‚å¯¾å‡¦ï¼‰
    if "```json" in output:
        start = output.find("```json") + 7
        end = output.find("```", start)
        output = output[start:end].strip()
    elif "```" in output:
        start = output.find("```") + 3
        end = output.find("```", start)
        output = output[start:end].strip()

    try:
        parsed = json.loads(output)
        log("  âœ… Opus JSON ãƒ‘ãƒ¼ã‚¹æˆåŠŸ")
        return parsed
    except json.JSONDecodeError as e:
        log(f"  âš ï¸ JSON ãƒ‘ãƒ¼ã‚¹å¤±æ•—: {e}")
        log(f"  ç”Ÿå‡ºåŠ›ï¼ˆå…ˆé ­500å­—ï¼‰: {output[:500]}")
        # ãƒ‘ãƒ¼ã‚¹å¤±æ•—ã§ã‚‚ç”Ÿãƒ†ã‚­ã‚¹ãƒˆã‚’è¿”ã™
        return {"raw_text": output, "parse_error": str(e)}


# =============================================================================
# Layer 1: åˆæˆãƒ¡ã‚¤ãƒ³
# =============================================================================

def synth(keys: dict, dry_run: bool = False) -> dict | None:
    """Layer 1: åé›† â†’ Opusåˆæˆ â†’ çµæœä¿å­˜ã€‚"""
    log("=== Layer 1: Opus 4.6 åˆæˆé–‹å§‹ ===")

    # Grok Xæ¤œç´¢ã‚’åˆæˆæ™‚ã«å®Ÿè¡Œï¼ˆ6æ™‚é–“ã”ã¨ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°ï¼‰
    collect(keys, grok_enabled=True)

    state = load_state()
    synthesis = run_opus_synthesis(state, dry_run=dry_run)
    if not synthesis or synthesis.get("dry_run"):
        return synthesis

    # åˆæˆçµæœã‚’ä¿å­˜
    ts = now_jst()
    synth_file = os.path.join(SYNTH_DIR, ts.strftime("%Y-%m-%d_%H") + ".json")
    with open(synth_file, "w") as f:
        json.dump(synthesis, f, ensure_ascii=False, indent=2)
    log(f"  åˆæˆçµæœä¿å­˜: {synth_file}")

    # state.json æ›´æ–°ï¼ˆé–‰ãƒ«ãƒ¼ãƒ—ï¼‰
    state["last_synthesis"] = ts.isoformat()
    state["next_context"] = synthesis.get("next_context", state.get("next_context"))
    if synthesis.get("new_claude_code_version"):
        state["top_claude_code_version"] = synthesis["new_claude_code_version"]
    if synthesis.get("new_openclaw_version"):
        state["top_openclaw_version"] = synthesis["new_openclaw_version"]
    if synthesis.get("better_tool_found"):
        state["known_best_ai_agent_tool"] = synthesis["better_tool_found"]
    # è¨˜äº‹ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³è¿½åŠ 
    for idea in synthesis.get("article_ideas", []):
        if idea not in state.get("article_pipeline", []):
            state.setdefault("article_pipeline", []).append(idea)
    # æœ€å¤§10ä»¶ã¾ã§
    state["article_pipeline"] = state.get("article_pipeline", [])[-10:]

    save_state(state)
    return synthesis


# =============================================================================
# Layer 2: Telegram å ±å‘Š
# =============================================================================

def format_telegram_report(synthesis: dict) -> str:
    """Opusåˆæˆçµæœã‚’ Telegram ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆ200å­—ä»¥å†…ã‚’ç›®æ¨™ï¼‰ã€‚"""
    ts = now_jst().strftime("%m/%d %H:%M JST")
    lines = [f"ğŸ¤– Hey Loop v2.0 â€” {ts}"]
    lines.append("")

    # æœ€é‡è¦ã‚¢ãƒ©ãƒ¼ãƒˆï¼ˆClaude Code/OpenClawå¤‰åŒ–ï¼‰
    alerts = []
    if synthesis.get("claude_code_alert"):
        alerts.append(f"âš¡ Claude Code: {synthesis['claude_code_alert']}")
    if synthesis.get("openclaw_alert"):
        alerts.append(f"âš¡ OpenClaw: {synthesis['openclaw_alert']}")
    if synthesis.get("better_tool_found"):
        alerts.append(f"ğŸš¨ æ–°ãƒ„ãƒ¼ãƒ«ç™ºè¦‹: {synthesis['better_tool_found']}")

    if alerts:
        lines.append("ã€ç·Šæ€¥ã‚¢ãƒ©ãƒ¼ãƒˆã€‘")
        lines.extend(alerts)
        lines.append("")

    # ãƒˆãƒƒãƒ—ç™ºè¦‹
    if synthesis.get("top_insight"):
        lines.append(f"ğŸ”¥ {synthesis['top_insight']}")
        lines.append("")

    # Naotoã¸ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
    if synthesis.get("action_for_naoto"):
        lines.append(f"â†’ ä»Šã™ã: {synthesis['action_for_naoto']}")
        lines.append("")

    # AIå‹•å‘
    devs = synthesis.get("ai_developments", [])
    if devs:
        lines.append("ğŸ“Š AIå‹•å‘:")
        for d in devs[:2]:
            lines.append(f"  â€¢ {d}")
        lines.append("")

    # åç›Šã‚·ã‚°ãƒŠãƒ«
    rev = synthesis.get("revenue_signals", [])
    if rev:
        lines.append("ğŸ’° åç›Šã‚·ã‚°ãƒŠãƒ«:")
        for r in rev[:2]:
            lines.append(f"  â€¢ {r}")
        lines.append("")

    # è¨˜äº‹å€™è£œ
    ideas = synthesis.get("article_ideas", [])
    if ideas:
        lines.append(f"ğŸ“° è¨˜äº‹å€™è£œ: {ideas[0]}")

    # ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼æ™‚
    if "raw_text" in synthesis:
        lines = [f"ğŸ¤– Hey Loop v2.0 â€” {ts}", ""]
        lines.append("âš ï¸ JSON ãƒ‘ãƒ¼ã‚¹å¤±æ•— â€” ç”Ÿãƒ†ã‚­ã‚¹ãƒˆ:")
        lines.append(synthesis["raw_text"][:500])

    return "\n".join(lines)


def send_telegram(token: str, chat_id: str, text: str, dry_run: bool = False):
    """Telegram ã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡ã€‚"""
    if dry_run:
        log("[dry-run] Telegram é€ä¿¡å†…å®¹:")
        print(text)
        print(f"ï¼ˆ{len(text)} å­—ï¼‰")
        return

    url = f"https://api.telegram.org/bot{token}/sendMessage"
    payload = {
        "chat_id": chat_id,
        "text": text,
        "parse_mode": "HTML",
        "disable_web_page_preview": True,
    }
    data = json.dumps(payload).encode("utf-8")
    req = urllib.request.Request(
        url, data=data,
        headers={"Content-Type": "application/json"},
        method="POST",
    )
    try:
        with urllib.request.urlopen(req, timeout=15) as resp:
            result = json.loads(resp.read().decode("utf-8"))
        if result.get("ok"):
            log("  âœ… Telegram é€ä¿¡æˆåŠŸ")
        else:
            log(f"  âŒ Telegram ã‚¨ãƒ©ãƒ¼: {result}")
    except Exception as e:
        log(f"  âŒ Telegram é€ä¿¡å¤±æ•—: {e}")


# =============================================================================
# Layer 4: é€±æ¬¡è‡ªå·±é€²åŒ–
# =============================================================================

def evolve(keys: dict, dry_run: bool = False):
    """é€±æ¬¡: éå»7æ—¥åˆ†ã® synthesis ã‚’ Opus ãŒåˆ†æ â†’ AGENT_WISDOM.md æ›´æ–°ã€‚"""
    log("=== Layer 4: é€±æ¬¡è‡ªå·±é€²åŒ– ===")

    claude_bin = find_claude_bin()
    if not claude_bin:
        log("  âŒ claude CLI ãªã—")
        return

    # éå»7æ—¥åˆ†ã® synthesis ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åé›†
    synth_files = sorted(Path(SYNTH_DIR).glob("*.json"))[-28:]  # æœ€å¤§28ãƒ•ã‚¡ã‚¤ãƒ«
    if not synth_files:
        log("  synthesis ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“")
        return

    # ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆã‚’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å«ã‚ã‚‹
    file_list = "\n".join([f"  - {f}" for f in synth_files])
    state = load_state()

    prompt = f"""ã‚ãªãŸã¯Hey Loop v2.0ã®è‡ªå·±é€²åŒ–ã‚¨ãƒ³ã‚¸ãƒ³ã§ã™ã€‚

## ã‚¿ã‚¹ã‚¯
éå»7æ—¥é–“ã®åˆ†æçµæœã‚’æŒ¯ã‚Šè¿”ã‚Šã€ã‚·ã‚¹ãƒ†ãƒ ã‚’æ”¹å–„ã—ã¦ãã ã•ã„ã€‚

## èª­ã‚€ã¹ããƒ•ã‚¡ã‚¤ãƒ«ï¼ˆRead ãƒ„ãƒ¼ãƒ«ã§èª­ã‚“ã§ãã ã•ã„ï¼‰
{file_list}

## ç¾åœ¨ã®çŠ¶æ…‹
{json.dumps(state, ensure_ascii=False, indent=2)[:1000]}

## ç¾åœ¨ã® AGENT_WISDOM.md
{AGENT_WISDOM_FILE}

## å‡ºåŠ›ï¼ˆJSONã®ã¿ï¼‰
{{
  "what_worked": ["åŠ¹æœãŒã‚ã£ãŸæƒ…å ±ãƒ»ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆæœ€å¤§5ä»¶ï¼‰"],
  "what_didnt_work": ["å½¹ã«ç«‹ãŸãªã‹ã£ãŸæƒ…å ±ã‚¿ã‚¤ãƒ—ï¼ˆæœ€å¤§3ä»¶ï¼‰"],
  "wisdom_to_add": ["AGENT_WISDOM.md ã«è¿½åŠ ã™ã¹ãæ•™è¨“ï¼ˆæœ€å¤§3ä»¶ï¼‰"],
  "topics_to_drop": ["ç›£è¦–ã‚’ã‚„ã‚ã‚‹ã¹ããƒˆãƒ”ãƒƒã‚¯ãƒ»ã‚½ãƒ¼ã‚¹"],
  "topics_to_add": ["æ–°ãŸã«ç›£è¦–ã™ã¹ããƒˆãƒ”ãƒƒã‚¯ãƒ»ã‚½ãƒ¼ã‚¹"],
  "weekly_summary": "1é€±é–“ã®ã‚µãƒãƒªãƒ¼ï¼ˆNaotoã¸ã€æ—¥æœ¬èª3æ–‡ï¼‰",
  "system_improvement": "ã‚¹ã‚¯ãƒªãƒ—ãƒˆãƒ»è¨­è¨ˆã¸ã®æ”¹å–„ææ¡ˆï¼ˆã‚ã‚Œã°ï¼‰",
  "flash_card_updates": [
    {{
      "key": "æ›´æ–°ãŒå¿…è¦ãªé …ç›®åï¼ˆä¾‹: X_API_PRICINGï¼‰",
      "old": "ç¾åœ¨FLASH_CARDS.mdã«æ›¸ã‹ã‚Œã¦ã„ã‚‹å†…å®¹ï¼ˆå¤‰åŒ–ãªã‘ã‚Œã°nullï¼‰",
      "new": "æ–°ã—ã„æ­£ç¢ºãªäº‹å®Ÿï¼ˆå¤‰åŒ–ãªã‘ã‚Œã°nullï¼‰",
      "reason": "ãªãœå¤‰æ›´ãŒå¿…è¦ã‹"
    }}
  ]
}}"""

    if dry_run:
        log("[dry-run] é€±æ¬¡é€²åŒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆå…ˆé ­300å­—ï¼‰:")
        print(prompt[:300])
        return

    log("Opus é€±æ¬¡åˆ†æä¸­...")
    try:
        result = subprocess.run(
            [claude_bin, "--print", prompt, "--allowedTools", "Read", "--output-format", "text"],
            capture_output=True, text=True, timeout=300, cwd=INTEL_DIR,
        )
    except subprocess.TimeoutExpired:
        log("  âŒ é€±æ¬¡åˆ†æã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ")
        return
    except Exception as e:
        log(f"  âŒ é€±æ¬¡åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
        return

    if result.returncode != 0:
        log(f"  âŒ çµ‚äº†ã‚³ãƒ¼ãƒ‰ {result.returncode}")
        return

    output = result.stdout.strip()
    # JSON æŠ½å‡º
    if "```json" in output:
        start = output.find("```json") + 7
        end = output.find("```", start)
        output = output[start:end].strip()

    try:
        weekly = json.loads(output)
    except Exception:
        log("  âš ï¸ é€±æ¬¡JSON ãƒ‘ãƒ¼ã‚¹å¤±æ•—")
        weekly = {"raw_text": output}

    # weekly çµæœã‚’ä¿å­˜
    ts = now_jst()
    weekly_file = os.path.join(WEEKLY_DIR, ts.strftime("%Y-%m-%d_weekly") + ".json")
    with open(weekly_file, "w") as f:
        json.dump(weekly, f, ensure_ascii=False, indent=2)
    log(f"  é€±æ¬¡çµæœä¿å­˜: {weekly_file}")

    # state ã«é€±æ¬¡ã‚¤ãƒ³ã‚µã‚¤ãƒˆã‚’è¨˜éŒ²
    state["weekly_insights"] = state.get("weekly_insights", [])
    state["weekly_insights"].append({
        "date": ts.isoformat(),
        "summary": weekly.get("weekly_summary", ""),
    })
    state["weekly_insights"] = state["weekly_insights"][-4:]  # ç›´è¿‘4é€±åˆ†ã®ã¿
    save_state(state)

    # Telegram ã«é€±æ¬¡ã‚µãƒãƒªãƒ¼ã‚’é€ä¿¡
    summary = weekly.get("weekly_summary", "é€±æ¬¡åˆ†æå®Œäº†")
    token = keys.get("telegram_token")
    chat_id = keys.get("telegram_chat")
    if token and chat_id:
        msg = f"ğŸ“ˆ Hey Loop é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆ\n\n{summary}"
        if weekly.get("wisdom_to_add"):
            msg += "\n\nğŸ’¡ æ–°ã—ã„æ•™è¨“:\n"
            for w in weekly["wisdom_to_add"]:
                msg += f"  â€¢ {w}\n"
        # â˜… FLASH_CARDSæ›´æ–°ææ¡ˆï¼ˆé‡è¦ï¼šã“ã‚ŒãŒã‚ã‚Œã°å¿…ãšClaudeã«é©ç”¨ã•ã›ã‚‹ï¼‰
        flash_updates = [u for u in weekly.get("flash_card_updates", []) if u.get("new")]
        if flash_updates:
            msg += "\n\nâš¡ FLASH_CARDS.md æ›´æ–°ãŒå¿…è¦:\n"
            for u in flash_updates:
                msg += f"  [{u['key']}] {u.get('old', '?')} â†’ {u['new']}\n  ç†ç”±: {u.get('reason', '')}\n"
            msg += "\nâ†’ Claude Codeã«ã€ŒFLASH_CARDSã‚’æ›´æ–°ã—ã¦ã€ã¨æŒ‡ç¤ºã—ã¦ãã ã•ã„"
        send_telegram(token, chat_id, msg)

    log("  âœ… é€±æ¬¡é€²åŒ–å®Œäº†")


# =============================================================================
# ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒã‚¤ãƒ³ãƒˆ
# =============================================================================

def main():
    parser = argparse.ArgumentParser(description="Hey Loop Intelligence Feed v2.0")
    parser.add_argument("--collect", action="store_true", help="Layer 0: åé›†ã®ã¿")
    parser.add_argument("--synth", action="store_true", help="Layer 1: Opusåˆæˆã®ã¿ï¼ˆåé›†ã‚‚å®Ÿè¡Œï¼‰")
    parser.add_argument("--evolve", action="store_true", help="Layer 4: é€±æ¬¡è‡ªå·±é€²åŒ–")
    parser.add_argument("--dry-run", action="store_true", help="Telegramé€ä¿¡ãªã—ï¼ˆãƒ†ã‚¹ãƒˆï¼‰")
    parser.add_argument("--no-grok", action="store_true", help="Grok Xæ¤œç´¢ã‚’ã‚¹ã‚­ãƒƒãƒ—")
    args = parser.parse_args()

    ensure_dirs()
    keys = get_api_keys()

    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼ˆå¼•æ•°ãªã—ï¼‰= ãƒ•ãƒ«å®Ÿè¡Œ
    if not any([args.collect, args.synth, args.evolve]):
        args.synth = True  # ãƒ•ãƒ«å®Ÿè¡Œ = synthï¼ˆå†…éƒ¨ã§ collect ã‚‚å‘¼ã¶ï¼‰

    if args.collect:
        collect(keys, grok_enabled=not args.no_grok)
        return

    if args.synth:
        synthesis = synth(keys, dry_run=args.dry_run)
        if synthesis and not synthesis.get("dry_run"):
            msg = format_telegram_report(synthesis)
            token = keys.get("telegram_token")
            chat_id = keys.get("telegram_chat")
            if token and chat_id:
                send_telegram(token, chat_id, msg, dry_run=args.dry_run)
            elif not args.dry_run:
                log("  âš ï¸ Telegram è¨­å®šãªã—ï¼ˆTELEGRAM_BOT_TOKEN / ALLOWED_USERSï¼‰")
                print("\n=== Telegram å ±å‘Šå†…å®¹ï¼ˆæœªé€ä¿¡ï¼‰ ===")
                print(msg)
        return

    if args.evolve:
        evolve(keys, dry_run=args.dry_run)
        return


if __name__ == "__main__":
    main()
